{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0869d4c-fe3b-4b65-a215-424b7ab2f202",
   "metadata": {},
   "source": [
    "※ このノートブックで扱うモデルの言語は英語となります。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d47d7-1b36-47d1-a3ba-4c8fcbb7c1e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 教育のための大規模言語モデル\n",
    "\n",
    "このノートブックでは、大規模言語モデル(LLM)を教育のユースケースに使う方法を示します。 \n",
    "LLMは要約、質問応答、質問と回答のペアの生成などのタスクに使用できます。\n",
    "\n",
    "このノートブックの最初の部分では、単一の `ml.p3.2xlarge` インスタンス上で **FLAN T5** モデルを使用して、SageMaker エンドポイントをセットアップします。 次に、エンドポイントへどのようにクエリできるかを示し、要約、質問応答、質問と回答のペアの生成のプロンプトを示すためにいくつかの小さなプログラムを追加します。\n",
    "\n",
    "最後のセクションは、量子コンピューティングに関する Wikipedia の記事、[Project Gutenberg](https://www.gutenberg.org/)の ebook テキスト、arxiv.org の科学的的な記事(pdf)、オーストラリアの 2023-24 年の予算に関する Medicare Overview のクエリを扱う、4 つのデモに分かれています。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940bc4c9-bcae-4f9a-87ff-958f2e152fdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.SageMaker Endpoint の設定\n",
    "\n",
    "### 1.1 Python 依存パッケージのインストール"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c62662a0-fa82-475c-b671-2ebeb67467ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade pip\n",
    "!pip install -U sagemaker\n",
    "!pip install -U langchain\n",
    "!pip install -U PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06225749-c2be-4050-bb3c-eea259b35ac9",
   "metadata": {},
   "source": [
    "### 1.2 SageMaker Endpoint のデプロイ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "011c244c-ca72-40f2-b7c9-7a94f25becf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json, logging\n",
    "from sagemaker import image_uris, instance_types, model_uris, script_uris\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.utils import name_from_base\n",
    "from IPython.display import display, HTML, IFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13b46906-f59b-439e-b10a-cc65725177dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('sagemaker')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20233a5f-08ce-4d04-bae4-379c32e9f0af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sagemaker==2.145.0\n",
      "Using boto3==1.26.111\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Using sagemaker=={sagemaker.__version__}')\n",
    "logger.info(f'Using boto3=={boto3.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9e633-bda5-462a-9108-f05f16f49060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの重みを保存するフォルダの作成\n",
    "!mkdir -p download_dir\n",
    "!mkdir -p source_documents_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "747d0e08-797c-4e34-8db0-274d9ab58d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sagemaker_session(local_download_dir) -> sagemaker.Session:\n",
    "    \"\"\"Return the SageMaker session.\"\"\"\n",
    "\n",
    "    sagemaker_client = boto3.client(\n",
    "        service_name=\"sagemaker\", region_name=boto3.Session().region_name\n",
    "    )\n",
    "\n",
    "    session_settings = sagemaker.session_settings.SessionSettings(\n",
    "        local_download_dir=local_download_dir\n",
    "    )\n",
    "\n",
    "    session = sagemaker.session.Session(\n",
    "        sagemaker_client=sagemaker_client, settings=session_settings\n",
    "    )\n",
    "\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84a5e29d-29af-4258-b107-a9d5a545e0b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using role arn:aws:iam::278313627171:role/service-role/AmazonSageMaker-ExecutionRole-20221130T152651 in region us-east-1\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = Session()\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "model_id, model_version = \"huggingface-text2text-flan-t5-xl\", \"*\"\n",
    "_model_env_variable_map = {\n",
    "    \"huggingface-text2text-flan-t5-xl\": {\"MMS_DEFAULT_WORKERS_PER_MODEL\": \"1\"},\n",
    "}\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-example-{model_id}\")\n",
    "instance_type = 'ml.p3.2xlarge'\n",
    "logger.info(f'Using role {aws_role} in region {aws_region}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cf0e09-a7e0-4bc4-9d0d-32aa3967bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace のコンテナイメージをベースにした、推論用 docker イメージの URI を取得します。\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # model_idから自動的に推定されます。\n",
    "    image_scope=\"inference\",\n",
    "    model_id=model_id,\n",
    "    model_version=model_version,\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "\n",
    "# モデルの読み込みや推論リクエストを処理するためのスクリプトの URI を取得します。このスクリプトには依存パッケージが含まれます。\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "# モデルの URI を取得します。\n",
    "model_uri = model_uris.retrieve(\n",
    "    model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    ")\n",
    "\n",
    "# SageMaker Model を作成します。\n",
    "if model_id in _model_env_variable_map:\n",
    "    # 大きなモデルに対して、私たちは既に推論スクリプトとモデルの詰め合わせを提供しています。\n",
    "    # そのため、（スクリプトのアップロードに使用される）source_dir は必須ではありません。\n",
    "    model = Model(\n",
    "        image_uri=deploy_image_uri,\n",
    "        model_data=model_uri,\n",
    "        role=aws_role,\n",
    "        predictor_cls=Predictor,\n",
    "        name=endpoint_name,\n",
    "        env=_model_env_variable_map[model_id],\n",
    "    )\n",
    "else:\n",
    "    model = Model(\n",
    "        image_uri=deploy_image_uri,\n",
    "        source_dir=deploy_source_uri,\n",
    "        model_data=model_uri,\n",
    "        entry_point=\"inference.py\",  # deploy_source_uri に含まれる entry point となるファイル\n",
    "        role=aws_role,\n",
    "        predictor_cls=Predictor,\n",
    "        name=endpoint_name,\n",
    "        sagemaker_session=get_sagemaker_session(\"download_dir\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4196fcc9-b25f-4c48-a030-a0bc30da9f0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # The following requires \"servicequotas:GetServiceQuota\"\n",
    "# sq = boto3.client('service-quotas')\n",
    "# response = sq.get_service_quota(\n",
    "#     ServiceCode='sagemaker',\n",
    "#     QuotaCode='L-1623D0BE'\n",
    "# )\n",
    "# quota = response['Quota']\n",
    "# print(f\"{quota['QuotaName']}: {quota['Value']}\")  # ml.p3.2xlarge for endpoint usage: 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26efc2da-eeab-406e-8a8a-b730e1c75e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating model with name: jumpstart-example-huggingface-text2text-2023-06-10-08-37-25-049\n",
      "CreateModel request: {\n",
      "    \"ModelName\": \"jumpstart-example-huggingface-text2text-2023-06-10-08-37-25-049\",\n",
      "    \"ExecutionRoleArn\": \"arn:aws:iam::278313627171:role/service-role/AmazonSageMaker-ExecutionRole-20221130T152651\",\n",
      "    \"PrimaryContainer\": {\n",
      "        \"Image\": \"763104351884.dkr.ecr.us-east-1.amazonaws.com/huggingface-pytorch-inference:1.13.1-transformers4.26.0-gpu-py39-cu117-ubuntu20.04\",\n",
      "        \"Environment\": {\n",
      "            \"MMS_DEFAULT_WORKERS_PER_MODEL\": \"1\"\n",
      "        },\n",
      "        \"ModelDataUrl\": \"s3://jumpstart-cache-prod-us-east-1/huggingface-infer/prepack/v1.1.0/infer-prepack-huggingface-text2text-flan-t5-xl.tar.gz\"\n",
      "    },\n",
      "    \"Tags\": [\n",
      "        {\n",
      "            \"Key\": \"aws-jumpstart-inference-model-uri\",\n",
      "            \"Value\": \"s3://jumpstart-cache-prod-us-east-1/huggingface-infer/prepack/v1.1.0/infer-prepack-huggingface-text2text-flan-t5-xl.tar.gz\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying endpoint jumpstart-example-huggingface-text2text-2023-06-10-08-37-25-049 on 1 x ml.p3.2xlarge (this will take approximately 6-8 minutes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating endpoint-config with name jumpstart-example-huggingface-text2text-2023-06-10-08-37-25-049\n",
      "Creating endpoint with name jumpstart-example-huggingface-text2text-2023-06-10-08-37-25-049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!CPU times: user 137 ms, sys: 14.1 ms, total: 151 ms\n",
      "Wall time: 6min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# モデルをデプロイします。Model クラスを使ってデプロイする場合、SageMaker API で推論するため、\n",
    "# Predictor クラスを受け取る必要があります。\n",
    "print(f'Deploying endpoint {endpoint_name} on 1 x {instance_type} (this will take approximately 6-8 minutes)')\n",
    "try:\n",
    "    model_predictor = model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type=instance_type,\n",
    "        predictor_cls=Predictor,\n",
    "        endpoint_name=endpoint_name,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f'Error: {e}')\n",
    "    print('Two common reasons for this error')\n",
    "    print('1. You are in a AWS region that does not have the ml.p3.2xlarge instance type')\n",
    "    print('2. You have exceeded the service quota of this AWS account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b47f6006-3b1a-48cb-847f-0891d084c30d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully deployed endpoint jumpstart-example-huggingface-text2text-2023-06-10-08-37-25-049 on 1 x ml.p3.2xlarge\n"
     ]
    }
   ],
   "source": [
    "print(f'Successfully deployed endpoint {endpoint_name} on 1 x {instance_type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fdab81-3874-4159-8b9b-b50db0d5b124",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. テキスト抽出とエンドポイントへクエリするためのサブルーチンの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ae3537-49e3-449d-9800-ef5a0797a9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "import requests\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option('max_colwidth', 80)  # Pandas Dataframe を表示するための最大幅を指定します。\n",
    "QNA_OUTPUT_STYLE = 'HTML'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02442d49-9e3b-41b9-a748-69ab1fab2470",
   "metadata": {},
   "source": [
    "### 2.1 PDF ファイルからのテキスト抽出\n",
    "\n",
    "PyPDF ライブラリを使用して、PDFファイルからテキストを抽出できます。（英語）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae4722ee-f380-4dd1-8afc-ea9d696aee34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_pages(pdf_file, max_pages=100):\n",
    "    pages = []\n",
    "    with open(pdf_file, 'rb') as f:\n",
    "        for i, page in enumerate(PyPDF2.PdfReader(f).pages):\n",
    "            if i == max_pages:\n",
    "                break\n",
    "            pages.append(page.extract_text())\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6f1bcb-b9ce-4a0d-8500-61505261db9c",
   "metadata": {},
   "source": [
    "### 2.2 URL からテキストベースのebookをダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b99ead0d-a80c-430d-991e-8724177fc88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download_url_text(url):\n",
    "    r = requests.get(url)\n",
    "    if r.status_code == 200:\n",
    "        return r.content.decode('utf-8')\n",
    "    else:\n",
    "        print(f'Failed to download {url}. Status code = {r.status_code}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d60aebb-384f-4c5b-96ca-897f500b4a96",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2.3 ウェブページから項目を抽出\n",
    "\n",
    "Beatiful Soup ライブラリを使用して、ウェブページのHTMLコンテンツをパースできます。\n",
    "ここでは、`<body>` セクションの中の `<p>` タグを抽出します。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0f280092-35bc-4f6b-9fc0-3a01bb4c58f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_paragraphs_from_html(text):\n",
    "    html = BeautifulSoup(text, 'html.parser')\n",
    "    return [ p.text for p in html.body.select('p') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d3f8d3-3ff4-4b1d-a51b-124bef928df2",
   "metadata": {},
   "source": [
    "### 2.4 Generate texts, or query an endpoint with prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7d291d-3f5d-445d-a263-39a02f47e7ef",
   "metadata": {},
   "source": [
    "### 2.4 テキストの生成とプロンプトを使ったエンドポイントへのクエリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "348db1eb-e8ff-4041-b75f-196c0e88384e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "newline, bold, unbold = '\\n', '\\033[1m', '\\033[0m'\n",
    "lightred, lightgreen, lightyellow, lightblue = '\\033[91m', '\\033[92m', '\\033[93m', '\\033[94m'\n",
    "lightmagenta, lightcyan, reset = '\\033[95m', '\\033[96m', '\\33[39m'\n",
    "\n",
    "def query_endpoint_with_json_payload(encoded_json):\n",
    "    client = boto3.client('runtime.sagemaker')\n",
    "    response = client.invoke_endpoint(EndpointName=endpoint_name, ContentType='application/json', Body=encoded_json)\n",
    "    return response\n",
    "\n",
    "def parse_response_multiple_texts(query_response):\n",
    "    model_predictions = json.loads(query_response['Body'].read())\n",
    "    generated_text = model_predictions['generated_texts']\n",
    "    return generated_text\n",
    "\n",
    "def generate_text_from_prompt(prompt, max_length=300, max_time=50, temperature=0.5,\n",
    "                              top_k=None, top_p=None, do_sample=True, seed=None):\n",
    "    payload = {\n",
    "        \"text_inputs\": prompt,\n",
    "        \"max_length\": max_length,\n",
    "        \"max_time\": max_time,\n",
    "        \"temperature\": temperature,\n",
    "        \"do_sample\": do_sample\n",
    "    }\n",
    "    if top_k is not None:\n",
    "        payload['top_k'] = top_k\n",
    "    if top_p is not None:\n",
    "        payload['top_p'] = top_p\n",
    "    if seed is not None:\n",
    "        payload['seed'] = seed\n",
    "\n",
    "    query_response = query_endpoint_with_json_payload(json.dumps(payload).encode('utf-8'))\n",
    "    return parse_response_multiple_texts(query_response)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823b36e1-28e3-4c29-881c-1d9c213656e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "大規模言語モデルの出力をさらにカスタマイズするために、以下のパラメータが利用可能です：\n",
    "\n",
    "* **max_length:**　モデルは出力長（入力コンテキストの長さを含む）が`max_length`に達するまでテキストを生成します。指定する場合は正の整数である必要があります。\n",
    "* **max_time:** 計算の実行を許可する最大時間を秒単位で指定します。この設定は、エンドポイント呼び出しの応答タイムアウトエラーが発生する前に応答を生成するのに役立ちます。\n",
    "* **num_return_sequences:** 返される出力列の数。指定する場合は正の整数である必要があります。\n",
    "* **num_beams:** 貪欲探索に使用されるビームの数。`num_return_sequences` 以上の整数である必要があります。\n",
    "\n",
    "* **no_repeat_ngram_size:** モデルが`no_repeat_ngram_size`の単語列が出力列で繰り返されないことを保証します。指定する場合は、1以上の正の整数である必要があります。\n",
    "* **temperature:** 出力のランダム性を制御します。temperature が高いほど確率の低い単語が出力され、低いほど確率の高い単語が出力されます。もし `temperature` -> 0 ならば、貪欲なデコード結果（確率が最大となる単語の列）となります。指定する場合は正の浮動小数点数である必要があります。\n",
    "* early_stopping:** Trueの場合、全ての仮説が文末トークンに到達した時点でテキスト生成を終了します。指定する場合、booleanである必要があります。\n",
    "* **do_sample:** Trueの場合、サンプリング戦略が有効になります。指定する場合、booleanである必要があります。\n",
    "* **top_k:** テキスト生成の各ステップにおいて、最も可能性の高い単語 `top_k` のみをサンプリングします。指定する場合、正の整数である必要があります。\n",
    "* **top_p:** テキスト生成の各ステップにおいて、累積確率 `top_p` で可能な最小の単語セットからサンプリングします。指定する場合、0から1の間の浮動小数点である必要があります。\n",
    "* **seed:** 再現性のためにランダム状態を固定します。指定する場合は整数である必要があります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "147e4af6-6cbd-4b57-ac28-6cbd715cb3e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def summarize(text, seed=None):\n",
    "    return generate_text_from_prompt(\n",
    "        f\"\"\"Summarize the following text in 100 words:\\n\\n{text}\\n\\nSummary:\"\"\",\n",
    "        temperature=0.2,  # 要約のための低い temperature\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "def ask(context, question, seed=None):\n",
    "    return generate_text_from_prompt(\n",
    "        f\"\"\"CONTEXT:\\n{context}\\n{question}\"\"\",\n",
    "        temperature=0.01,  # 正確性のための最も低いtempereature\n",
    "        max_length=150,    # 回答が冗長すぎないように設定\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "def extract_question(text, seed=None):\n",
    "    return generate_text_from_prompt(\n",
    "        f\"\"\"EXTRACT QUESTIONS\\nContext:\\n{text}\\nQuestion:\"\"\",\n",
    "        temperature=1.0,  # 創造性のための最大のtemperature\n",
    "        seed=seed\n",
    "    )\n",
    "\n",
    "def create_qna_pairs(text, n, output_style='HTML', seed=None):\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for i in range(n):\n",
    "        qn = extract_question(text, seed) if i == 0 else extract_question(text)\n",
    "        questions.append(qn)\n",
    "        answers.append(ask(text, qn))\n",
    "        if output_style == 'HTML':\n",
    "            output = \\\n",
    "            f\"\"\"<b>{i+1}</b>. <b><font color=#FF7F50>Question</font></b>: {questions[i]}\n",
    "            <b><font color=#FA8072>Answer</font></b>: {answers[i]}\"\"\"\n",
    "            display(HTML(output))\n",
    "        elif output_style == 'text':\n",
    "            print(f\"\"\"{i+1}. {lightblue}{bold}Question{unbold}{reset}: {questions[i]} {lightcyan}{bold}Answer{unbold}{reset}: {answers[i]}\"\"\")\n",
    "    if output_style == 'table':\n",
    "        return pd.DataFrame({\n",
    "            'Question': questions,\n",
    "            'Answer': answers\n",
    "        }).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa55310f-fab2-40d8-aa5a-0e2b2588adb0",
   "metadata": {},
   "source": [
    "## 3. LLM Demos for Education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c33aebb-2ecf-4faf-b8f9-fab209e5b6f1",
   "metadata": {},
   "source": [
    "## 3. 教育のための LLM デモ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496c9c1-108e-44ad-a0ab-baf1cbc7e61f",
   "metadata": {},
   "source": [
    "このノートブックでは、以下のテキストを使ってテキストの要約と、質問と回答のペアの生成を行います。\n",
    "\n",
    "1. Wikipediaの量子コンピューティングに関する記述: https://en.wikipedia.org/wiki/Quantum_computing\n",
    "<!-- 1. Quantum Computing and Quantum Information (by Nielsen & Chuang): https://michaelnielsen.org/qcqi/QINFO-book-nielsen-and-chuang-toc-and-chapter1-nov00.pdf (this is a sample chapter from [this website](https://michaelnielsen.org/qcqi/)) -->\n",
    "2. くまのプーさん (by Alan Alexander Milne): https://www.gutenberg.org/ebooks/67098.txt.utf-8\n",
    "3. アテンションに関する論文 Attention is all you need (by Vaswani et al): https://arxiv.org/pdf/1706.03762.pdf\n",
    "4. オーストラリアの2023-24年の予算概要: https://budget.gov.au/content/overview/download/budget_overview-20230511.pdf\n",
    "\n",
    "このノートブックでは、シンプルで簡単にデプロイできる Flan T5 XL モデルを使っています。\n",
    "さらに良い結果を得るためにファインチューニングや改善されたモデルを使うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085e7c1c-8dbc-4e50-bc26-b811892d8b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# curl コマンドを利用して、pdfとテキストをダウンロードしあmす。\n",
    "# リダイレクトを許可する `-L` とサイレントモードの `-s`、出力ファイルを指定するための `-o` を指定しています。\n",
    "\n",
    "# アテンションに関する論文 Attention is all you need (by Vaswani et al)\n",
    "!curl -Ls https://arxiv.org/pdf/1706.03762.pdf -o source_documents_dir/attention.pdf\n",
    "# オーストラリアの2023-24年の予算概要\n",
    "!curl -Ls https://budget.gov.au/content/overview/download/budget_overview-20230511.pdf -o source_documents_dir/aus_budget_overview-2023-24.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94bf0a4-119a-4f34-bcb2-d198b4785d58",
   "metadata": {},
   "source": [
    "### 3.1 量子コンピュータに関するWikipediaのページ\n",
    "\n",
    "この例では、量子コンピュータに関する Wikipedia のページを context として使用します。\n",
    "LLM は キーワード生成、要約、質問と回答のペア作成 に使います。\n",
    "好みに合わせて、WikipediaのURL、ウェブサイトやブログ、新しい記事になどに変更できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e7e5d3-016c-47d1-824f-14cf42709999",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCHARS = 400     # 抽出したテキストの最初の400文字を使います。より多くのコンテキストが必要なら増やします。\n",
    "NQUESTIONS = 10  # 生成する質問回答のペアの個数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0225b-ebe3-445b-80dc-b6debb27aa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_paragraphs = extract_paragraphs_from_html(\n",
    "    download_url_text('https://en.wikipedia.org/wiki/Quantum_computing')\n",
    ")[1:11]  # 最初の2つのパラグラフは飛ばします。\n",
    "wiki_txt = '\\n\\n'.join(wiki_paragraphs)\n",
    "# print(f'{txt1[:NCHARS]}...\\n\\n...{txt1[-NCHARS:]}')\n",
    "IFrame('https://en.wikipedia.org/wiki/Quantum_computing', width=800, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a891c-e574-4ea3-ac7f-0d01e52aa38e",
   "metadata": {},
   "source": [
    "#### Key word Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf755b7b-d93c-425c-a4ef-b77a12c7e264",
   "metadata": {},
   "source": [
    "#### キーワード生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "114fd4e1-c7c7-4ab4-9a85-4f057bafb4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantum, computing, superposition, qubit\n"
     ]
    }
   ],
   "source": [
    "KEY_WORDS = generate_text_from_prompt(\n",
    "    f'FIND KEY WORDS\\n\\nContext:\\n{wiki_txt}\\nKey Words:',\n",
    "    seed=12345\n",
    ")\n",
    "key_word_list = KEY_WORDS.split(', ')\n",
    "print(KEY_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efc0f1c-1ee2-4d5c-ba37-f0f0a4755fd4",
   "metadata": {},
   "source": [
    "#### キーポイントの要約\n",
    "\n",
    "パラグラフごとに、短い要約を作成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe371a26-340a-41d3-9138-36479871dce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary = []\n",
    "for i, x in enumerate(wiki_paragraphs):\n",
    "    summary.append(f'{i+1}. {summarize(x[:1500])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "284d81bd-fb49-46d6-8142-9a8b8393e504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Key Points</h4><li>1. A quantum computer is a computer that exploits quantum mechanical phenomena.</li>\n",
       "<li>2. Quantum computing is a branch of computer science that uses quantum mechanics to perform calculations.</li>\n",
       "<li>3. Qubits are the building blocks of quantum computing.</li>\n",
       "<li>4. Quantum computing is the study of the computational complexity of problems with respect to quantum computers.</li>\n",
       "<li>5. The field of quantum computing has been developing rapidly in recent years, largely due to the development of quantum computing hardware and software.</li>\n",
       "<li>6. The field of quantum computing has been developing rapidly since the 1980s.</li>\n",
       "<li>7. Quantum computing was first proposed in the 1980s by the late Richard Feynman, who was a pioneer in the field of quantum theory.</li>\n",
       "<li>8. Quantum computing is the development of a computer that uses quantum physics to perform computations that are impossible for classical computers.</li>\n",
       "<li>9. The emergence of quantum computing has been a major factor in the development of quantum computing.</li>\n",
       "<li>10. Quantum computing is a new field of research.</li>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\n",
    "    '<h4>Key Points</h4>' + \n",
    "    '\\n'.join([ f'<li>{x}</li>' for x in summary ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da5e48-ed29-400b-9066-c68b350daa01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上記の 10 個のポイントは短い要約をつくるために使うことができます。\n",
    "summarize('\\n'.join(summary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b797382-520c-42ae-83aa-8b25778e255b",
   "metadata": {},
   "source": [
    "#### 正答であるかのチェック\n",
    "\n",
    "この例では、テキストをベースに \"正しい回答\" を作成します。\n",
    "生徒が作成した、誤った回答 と 正しい回答（公式の回答は言い方が異なる正答） を1つずつ作成したとします。\n",
    "LLMを使って生徒の回答が正しいかどうかをチェックします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b40942c-d2fc-4121-8143-a5875d5d4f66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A quantum computer is a computer that exploits quantum mechanical phenomena.\n"
     ]
    }
   ],
   "source": [
    "prompt=f\"\"\"Context:{wiki_txt}\n",
    "What is quantum computing?\"\"\"\n",
    "answer = generate_text_from_prompt(prompt, temperature=0.01)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c12861c0-991c-4690-8a2c-a6d655ab3742",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n"
     ]
    }
   ],
   "source": [
    "prompt=f\"\"\"Context:{wiki_txt}\n",
    "Question: What is quantum computing?\n",
    "Answer: {answer}\n",
    "Student: Quantum computing is using computers with quantum dots\n",
    "Is this answer correct?\"\"\"\n",
    "print(generate_text_from_prompt(prompt, temperature=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3d663433-8b29-4dfe-8e11-542c48ab919e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "prompt=f\"\"\"Context:{wiki_txt}\n",
    "Question: What is quantum computing?\n",
    "Answer: {answer}\n",
    "Student: Quantum computing involves using computers that make use of quantum mechanics\n",
    "Is this answer correct?\"\"\"\n",
    "print(generate_text_from_prompt(prompt, temperature=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bb43ac-678b-40c7-98b5-301f7168dd8d",
   "metadata": {},
   "source": [
    "#### 質問と回答のペア生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cd4876c-b5cb-498d-ac7f-0b0b52c415a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>1</b>. <b><font color=#FF7F50>Question</font></b>: What limits the applications in non-cryptological domains?\n",
       "            <b><font color=#FA8072>Answer</font></b>: the current state of the art is largely experimental and impractical"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>2</b>. <b><font color=#FF7F50>Question</font></b>: What is a qubit?\n",
       "            <b><font color=#FA8072>Answer</font></b>: The basic unit of information in quantum computing"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>3</b>. <b><font color=#FF7F50>Question</font></b>: What was the breakthrough that demonstrated the feasibility of the quantum computing?\n",
       "            <b><font color=#FA8072>Answer</font></b>: a two-qubit quantum computer"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>4</b>. <b><font color=#FF7F50>Question</font></b>: Why might quantum computers be considered superior over classical computers?\n",
       "            <b><font color=#FA8072>Answer</font></b>: quantum algorithms for certain problems have significantly lower time complexities than corresponding known classical algorithms"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>5</b>. <b><font color=#FF7F50>Question</font></b>: What computing unit is described?\n",
       "            <b><font color=#FA8072>Answer</font></b>: qubit"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>6</b>. <b><font color=#FF7F50>Question</font></b>: How is quantum computing differentiated from classical computing?\n",
       "            <b><font color=#FA8072>Answer</font></b>: quantum algorithms for certain problems have significantly lower time complexities than corresponding known classical algorithms"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>7</b>. <b><font color=#FF7F50>Question</font></b>: What type of machines are considered the best for quantum computing?\n",
       "            <b><font color=#FA8072>Answer</font></b>: superconductors"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>8</b>. <b><font color=#FF7F50>Question</font></b>: Why is it hard to create scalable qubits?\n",
       "            <b><font color=#FA8072>Answer</font></b>: If a physical qubit is not sufficiently isolated from its environment, it suffers from quantum decoherence, introducing noise into calculations"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>9</b>. <b><font color=#FF7F50>Question</font></b>: What happened when quantum theory and computer science began to merge?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Paul Benioff introduced the quantum Turing machine, which uses quantum theory to describe a simplified computer"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>10</b>. <b><font color=#FF7F50>Question</font></b>: How is the quantum computer different from a classical computer?\n",
       "            <b><font color=#FA8072>Answer</font></b>: a qubit can exist in a superposition of its two \"basis\" states, which loosely means that it is in both states simultaneously"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_qna_pairs(wiki_txt, NQUESTIONS, output_style=QNA_OUTPUT_STYLE, seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea01b19d-0ab0-4511-81ad-b2f8f9072df3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2 くまのプーさん (by Alan Alexander Milne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a832c-4acc-405c-9e0a-70f55d26513b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "winnie_the_pooh = download_url_text('https://www.gutenberg.org/ebooks/67098.txt.utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "89f2bd54-248a-45b1-a882-2159f0a9e4df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER III\n",
      "\n",
      "                   IN WHICH POOH AND PIGLET GO HUNTING\n",
      "                        AND NEARLY CATCH A WOOZLE\n",
      "\n",
      "\n",
      "The Piglet lived in a very grand house in the middle of a beech-tree,\n",
      "and the beech-tree was in the middle of the forest, and the Piglet lived\n",
      "in the middle of the house. Next to his house was a piece of broken\n",
      "board which had: \"TRESPASSERS W\" on it. When Christopher Robin asked the\n",
      "Piglet what it meant, he said it was his grandfather's name, and had\n",
      "been in the family for a long time, Christopher Robin said you\n",
      "_couldn't_ be called Trespassers W, and Piglet said yes, you could,\n",
      "because his grandfather was, and it was short for Trespassers Will,\n",
      "which was short for Trespassers William. And his grandfather had had two\n",
      "names in case he lost one--Trespassers after an uncle, and William after\n",
      "Trespassers.\n",
      "\n",
      "\"I've got two names,\" said Christopher Robin carelessly.\n",
      "\n",
      "\"Well, there you are, that proves it,\" said Piglet.\n",
      "\n",
      "One fine winter's day when Piglet was brushing away the snow in front of\n",
      "his house, he happened to look up, and there was Winnie-the-Pooh. Pooh\n",
      "was walking round and round in a circle, thinking of something else, and\n",
      "when Piglet called to him, he just went on walking.\n",
      "\n",
      "\"Hallo!\" said Piglet, \"what are _you_ doing?\"\n",
      "\n",
      "\"Hunting,\" said Pooh.\n",
      "\n",
      "\"Hunting what?\"\n",
      "\n",
      "\"Tracking something,\" said Winnie-the-Pooh very mysteriously.\n",
      "\n",
      "\"Tracking what?\" said Piglet, coming closer.\n",
      "\n",
      "\"That's just what I ask myself. I ask myself, What?\"\n",
      "\n",
      "\"What do you think you'll answer?\"\n",
      "\n",
      "\"I shall have to wait until I catch up with it,\" said Winnie-the-Pooh.\n",
      "\"Now, look there.\" He pointed to the ground in front of him. \"What do\n",
      "you see there?\"\n",
      "\n",
      "\"Tracks,\" said Piglet. \"Paw-marks.\" He gave a little squeak of\n",
      "excitement. \"Oh, Pooh! Do you think it's a--a--a Woozle?\"\n",
      "\n",
      "\"It may be,\" said Pooh. \"Sometimes it is, and sometimes it isn't. You\n",
      "never can tell with paw-marks.\"\n",
      "\n",
      "With these few words he went on tracking, and Piglet, after watching him\n",
      "for a minute or two, ran after him. Winnie-the-Pooh had come to a sudden\n",
      "stop, and was bending over the tracks in a puzzled sort of way.\n",
      "\n",
      "\"What's the matter?\" asked Piglet.\n",
      "\n",
      "\"It's a very funny thing,\" said Bear, \"but there seem to be\n",
      "_two_ animals now. This--whatever-it-was--has been joined by\n",
      "another--whatever-it-is--and the two of them are now proceeding\n",
      "in company. Would you mind coming with me, Piglet, in case they\n",
      "turn out to be Hostile Animals?\"\n",
      "\n",
      "Piglet scratched his ear in a nice sort of way, and said that he had\n",
      "nothing to do until Friday, and would be delighted to come, in case it\n",
      "really _was_ a Woozle.\n",
      "\n",
      "\"You mean, in case it really is two Woozles,\" said Winnie-the-Pooh, and\n",
      "Piglet said that anyhow he had nothing to do until Friday. So off they\n",
      "went together.\n",
      "\n",
      "There was a small spinney of larch trees just here, and it seemed as if\n",
      "the two Woozles, if that is what they were, had been going round this\n",
      "spinney; so round this spinney went Pooh and Piglet after them; Piglet\n",
      "passing the time by telling Pooh what his Grandfather Trespassers W had\n",
      "done to Remove Stiffness after Tracking, and how his Grandfather\n",
      "Trespassers W had suffered in his later years from Shortness of Breath,\n",
      "and other matters of interest, and Pooh wondering what a Grandfather was\n",
      "like, and if perhaps this was Two Grandfathers they were after now, and,\n",
      "if so, whether he would be allowed to take one home and keep it, and\n",
      "what Christopher Robin would say. And still the tracks went on in front\n",
      "of them....\n",
      "\n",
      "Suddenly Winnie-the-Pooh stopped, and pointed excitedly in front of him.\n",
      "\"_Look!_\"\n",
      "\n",
      "\"_What?_\" said Piglet, with a jump. And then, to show that he hadn't\n",
      "been frightened, he jumped up and down once or twice more in an\n",
      "exercising sort of way.\n",
      "\n",
      "\"The tracks!\" said Pooh. \"_A third animal has joined the other two!_\"\n",
      "\n",
      "\"Pooh!\" cried Piglet. \"Do you think it is another Woozle?\"\n",
      "\n",
      "\"No,\" said Pooh, \"because it makes different marks. It is either Two\n",
      "Woozles and one, as it might be, Wizzle, or Two, as it might be, Wizzles\n",
      "and one, if so it is, Woozle. Let us continue to follow them.\"\n",
      "\n",
      "So they went on, feeling just a little anxious now, in case the three\n",
      "animals in front of them were of Hostile Intent. And Piglet wished very\n",
      "much that his Grandfather T. W. were there, instead of elsewhere, and\n",
      "Pooh thought how nice it would be if they met Christopher Robin suddenly\n",
      "but quite accidentally, and only because he liked Christopher Robin so\n",
      "much. And then, all of a sudden, Winnie-the-Pooh stopped again, and\n",
      "licked the tip of his nose in a cooling manner, for he was feeling more\n",
      "hot and anxious than ever in his life before. _There were four animals\n",
      "in front of them!_\n",
      "\n",
      "\"Do you see, Piglet? Look at their tracks! Three, as it were, Woozles,\n",
      "and one, as it was, Wizzle. _Another Woozle has joined them!_\"\n",
      "\n",
      "And so it seemed to be. There were the tracks; crossing over each other\n",
      "here, getting muddled up with each other there; but, quite\n"
     ]
    }
   ],
   "source": [
    "x = winnie_the_pooh.find('CHAPTER III')\n",
    "pooh_txt = winnie_the_pooh[x:x+5000]  # Extract the first 5000 characters of chapter 3\n",
    "print(pooh_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12093ffc-c62d-49d7-889e-1fec005a4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = winnie_the_pooh.find('CHAPTER III')\n",
    "pooh_txt = winnie_the_pooh[x:x+5000]  # チャプター3の最初の5000文字を抽出します\n",
    "print(pooh_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c62792e0-f044-4c34-aa19-b8126f5d0b61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Piglet lived in a very grand house in the middle of a beech-tree, and the beech-tree was in the middle of the forest, and the Piglet lived in the middle of the house. Next to his house was a piece of broken board which had: \"TRESPASSERS W\" on it. When Christopher Robin asked the Piglet what it meant, he said it was his grandfather\\'s name, and had been in the family for a long time. Christopher Robin said you _could_ be called Trespassers W, and Piglet said yes, you could, because his grandfather was, and it was short for Trespassers Will'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(pooh_txt, \"What is the storyline here?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55b3aad2-2775-41b8-b669-0df6a31d4c56",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Winnie-the-Pooh'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(pooh_txt, \"Who is the main character?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5fc08e87-7445-45a6-a3a5-1edac39dc696",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Winnie-the-Pooh and Piglet nearly catch a Woozle.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(pooh_txt, \"What happens at the end?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c2c908fd-9ba1-4bf7-9f36-c8767afd92ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>1</b>. <b><font color=#FF7F50>Question</font></b>: Who thought the three woozles in front of them might be dangerous to them?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Winnie-the-Pooh"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>2</b>. <b><font color=#FF7F50>Question</font></b>: What did the broken board say?\n",
       "            <b><font color=#FA8072>Answer</font></b>: \"TRESPASSERS W\""
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>3</b>. <b><font color=#FF7F50>Question</font></b>: What was needed to be considered when using paw-marks?\n",
       "            <b><font color=#FA8072>Answer</font></b>: different animals"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>4</b>. <b><font color=#FF7F50>Question</font></b>: Why did Piglet's grandfather have two names?\n",
       "            <b><font color=#FA8072>Answer</font></b>: in case he lost one"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>5</b>. <b><font color=#FF7F50>Question</font></b>: What did Piglet and Winnie 'the-Pooh notice before the two of them noticed each other?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Tracks"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>6</b>. <b><font color=#FF7F50>Question</font></b>: Why didn't the \"trespassers W\" sign spell the proper name for the Piglet?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Christopher Robin said you _couldn't_ be called Trespassers W, and Piglet said yes, you could, because his grandfather was, and it was short for Trespassers Will, which was short for Trespassers William."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>7</b>. <b><font color=#FF7F50>Question</font></b>: Why was it so interesting that Trespasser WILL was short for Trespassers William\n",
       "            <b><font color=#FA8072>Answer</font></b>: Trespassers W was short for Trespassers Will, which was short for Trespassers William."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>8</b>. <b><font color=#FF7F50>Question</font></b>: Why were there different animal tracks around the spinney?\n",
       "            <b><font color=#FA8072>Answer</font></b>: The Woozles were not the same animal."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>9</b>. <b><font color=#FF7F50>Question</font></b>: What was the name of the three animals they were following\n",
       "            <b><font color=#FA8072>Answer</font></b>: Woozles"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>10</b>. <b><font color=#FF7F50>Question</font></b>: Who left the other animals behind?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Wizzle"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_qna_pairs(pooh_txt, NQUESTIONS, output_style=QNA_OUTPUT_STYLE, seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4a04ca-0d03-4a06-94e6-1d497b459b03",
   "metadata": {},
   "source": [
    "### 3.3 アテンションに関するAttention is all you need (by Vaswani et al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b93e8343-42b5-4368-ad82-1b8cb90be303",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "attention = extract_pages('source_documents_dir/attention.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e59b3356-fa39-4ba7-849d-f1c5aeb98886",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"400\"\n",
       "            src=\"source_documents_dir/attention.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fb730d42610>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_txt = '\\n\\n'.join(attention[1:3] + attention[9:10])  # We will use pages 1, 2 (for the intro), and 9 (for the conclusion)\n",
    "# print(f'{attention_txt[:NCHARS]}...\\n\\n\\n...{attention_txt[-NCHARS:]}')\n",
    "IFrame('source_documents_dir/attention.pdf', width=800, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c25f9d-05e6-4b68-9d17-eedf3915479b",
   "metadata": {},
   "source": [
    "#### 質問回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "edbf35b5-2c79-4924-a50b-49e6fef53c38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output. The Transformer allows for significantly more parallelization and can reach a new state of the art in translation quality after being trained for as little as twelve hours on eight P100 GPUs.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(attention_txt, \"What is the main gist of the paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8674d667-7411-40ab-8b4c-90ce98ef1581",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Transformer is the first sequence transduction model relying entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(attention_txt, \"What is the problem being solved?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e69d7c38-d788-41f1-a7f0-5abf463c0a73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Transformer is the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(attention_txt, \"What is the conclusion of the paper?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ef8c05dc-a837-4454-b1aa-d13345dee2be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text will be split up into chunks of 1202 characters and summarized\n"
     ]
    }
   ],
   "source": [
    "chunk_size = len(attention_txt)//8\n",
    "print(f'The text will be split up into chunks of {chunk_size} characters and summarized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf3771d6-11de-416e-be0c-ac91b84d93f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Key Points</h4>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "1. The emergence of recurrent models and encoder-decoder architectures in language modeling and transduction has been a major factor in the development of a wide range of models for language modeling and transduction."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "2. Attention mechanisms have been used in a variety of models to reduce the number of operations required to draw global dependencies between input and output positions [1,2,3,7,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,41,42,43,44,45,46,47,48,49,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,75,76,77,78,79,80,81,82,83,84,85,88,89,90,91,92,93,94,95,96,97,98,99,99,100,101,102,103,104,105,106,107,108,109,110,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111,111"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "3. The Transformer is a model for transduction of sequences of inputs and outputs based on self-attention."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "4. odels have an encoder-decoder structure [ 5,2,35]. The Transformer follows this overall architecture using stacked self-attention and point-wise, fully connected layers for both the encoder and decoder, shown in the left and right halves of Figure 1, respectively. 3.1 Encoder and Decoder Stacks Encoder: The encoder is composed of a stack of N= 6 identical layers. Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position- wise fully connected feed-forward network. We employ a residual connection [ 11] around each of the two sub-layers, followed by layer normalization [ 1]. That is, the output of each sub-layer is LayerNorm( x+ Sublayer( x)), where Sublayer( x) is the function implemented by the sub-layer i."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "5. te encoder: The decoder is also composed of a stack of N= 6 identical layers. In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. Similar to the encoder, we employ residual connections around each of the sub-layers, followed by layer normalization."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "6. We present a small-data RNN model for German-to-English translation."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "7. Transformer, the first sequence transduction model based entirely on attention, replaces the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles. We are excited about the future of attention-based models and plan to apply them to other tasks. We plan to extend the Transformer to problems involving input and output modalities other than text and to investigate local, restricted attention mechanisms to efficiently handle large input and output modalities such as images, audio and video."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "8. We present a new model for machine translation that is able to learn a tensor representation of the target language and a tensor representation of the target language."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<h4>Key Points</h4>'))\n",
    "summary = []\n",
    "for i in range(8):\n",
    "    x0 = i*chunk_size\n",
    "    x1 = (i+1)*chunk_size\n",
    "    line_summary = f'{i+1}. {summarize(attention_txt[x0:x1])}'\n",
    "    display(HTML(line_summary))\n",
    "    summary.append(line_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b10a987c-c5f6-4d99-a587-1aadf5b37878",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>1</b>. <b><font color=#FF7F50>Question</font></b>: What is the architecture of their model?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Most competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,35]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>2</b>. <b><font color=#FF7F50>Question</font></b>: What is Transformer and how is the architecture different from usual models?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Transformer is the first transduction model relying entirely on self-attention to compute representations of its input and output without using sequence- aligned RNNs or convolution."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>3</b>. <b><font color=#FF7F50>Question</font></b>: What type of architecture do they use?\n",
       "            <b><font color=#FA8072>Answer</font></b>: a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>4</b>. <b><font color=#FF7F50>Question</font></b>: How is Transformer architected?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Model Architecture Most competitive neural sequence transduction models have an encoder-decoder structure [5,2,35]. Here, the encoder maps an input sequence of symbol representations (x1;:::;x n)to a sequence of continuous representations z= (z1;:::;z n). Given z, the decoder then generates an output sequence (y1;:::;y m)of symbols one element at a time. At each step the model is auto-regressive [10,11], consuming the previously generated symbols as additional input when generating the next. The Transformer follows this overall architecture using stacked self-attention"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>5</b>. <b><font color=#FF7F50>Question</font></b>: What is the model architecture of Transformer model?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Most competitive neural sequence transduction models have an encoder-decoder structure [ 5,2,35]"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>6</b>. <b><font color=#FF7F50>Question</font></b>: What method do we introduce to represent the output information as a binary vector using attention mechanisms based on the previous vectors?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Transformer"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>7</b>. <b><font color=#FF7F50>Question</font></b>: What is a Transformer model?\n",
       "            <b><font color=#FA8072>Answer</font></b>: We propose the Transformer, a model architecture eschewing recurrence and instead relying entirely on an attention mechanism to draw global dependencies between input and output."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>8</b>. <b><font color=#FF7F50>Question</font></b>: How does Transformer improve the state-of-the-art model on English-to-German and English-to-French toyota j250+?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Transformer is the first transduction model relying entirely on attention to compute representations of its input and output without using sequence- aligned RNNs or convolution."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>9</b>. <b><font color=#FF7F50>Question</font></b>: What does Transformer rely on other than recurrent layers?\n",
       "            <b><font color=#FA8072>Answer</font></b>: attention mechanism"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>10</b>. <b><font color=#FF7F50>Question</font></b>: Does the Transformer achieve state of the art compared to the previous state of the art models\n",
       "            <b><font color=#FA8072>Answer</font></b>: Yes"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_qna_pairs(attention_txt, NQUESTIONS, output_style=QNA_OUTPUT_STYLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9bc216-0d2e-454b-b1d3-7d909afb17ea",
   "metadata": {},
   "source": [
    "### 3.4 オーストラリアの 2023-24年の予算概要 (Medicare)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addc9898-b6f7-4d58-af4b-a8fc32fab1dd",
   "metadata": {},
   "source": [
    "この例では、オーストラリアの 2023-24年の予算をみて、メディケアの改善に着目します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b747aa8a-bc64-45a6-ad40-37a30d8b483d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historic investment in Medicare \n",
      "Strengthening Medicare\n",
      "Medicare is the foundation of Australia’s primary health care system. In this \n",
      "Budget, the Government is investing $5.7 billion over 5 years from 2022—23 to \n",
      "strengthen Medicare and make it cheaper and easier to see a doctor.\n",
      "The Strengthening Medicare package includes the largest investment in bulk \n",
      "billing incentives ever. The Government is...\n",
      "\n",
      "\n",
      "...llion over 4 years to establish the Primary Care and Midwifery \n",
      "Scholarships program, supporting registered nurses and midwives in \n",
      "post-graduate study to improve their skills \n",
      "• $31.6 million over 2 years for improved training arrangements for \n",
      "international medical students working rur al and remote locations.\n",
      "26 Strengthening MedicareStronger foundations for a better future   |   Budget 2023–24\n"
     ]
    }
   ],
   "source": [
    "# Extracting the pages from the Budget overview and work on the pages 24 to 27 (Medicare related)\n",
    "aus_budget_overview = extract_pages('source_documents_dir/aus_budget_overview-2023-24.pdf')\n",
    "txt_aus_budget_overview_medicare = '\\n\\n'.join(aus_budget_overview[24:27])  # We will use pages 24 to 27. Those pages cover the Medicare budget.\n",
    "print(f'{txt_aus_budget_overview_medicare[:NCHARS]}...\\n\\n\\n...{txt_aus_budget_overview_medicare[-NCHARS:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b82a298-4208-4666-8a61-fa760f8f6241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# メディケアに関連する 24 から 27 ページを抽出します。\n",
    "aus_budget_overview = extract_pages('source_documents_dir/aus_budget_overview-2023-24.pdf')\n",
    "txt_aus_budget_overview_medicare = '\\n\\n'.join(aus_budget_overview[24:27])  # メディケアの予算に関する予算をカバーする 24 から 27 ページを使います。\n",
    "print(f'{txt_aus_budget_overview_medicare[:NCHARS]}...\\n\\n\\n...{txt_aus_budget_overview_medicare[-NCHARS:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46242956-d094-4c84-a2ec-aa6fa76c6765",
   "metadata": {},
   "source": [
    "#### 質問回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "068785da-9875-4d05-bcd6-e9354e59b934",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Government is investing $5.7 billion over 5 years from 2022-23 to strengthen Medicare and make it cheaper and easier to see a doctor.'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(txt_aus_budget_overview_medicare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ccd65b47-502d-4cd9-8896-a03160bf7415",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>1</b>. <b><font color=#FF7F50>Question</font></b>: How many Australians will be enabled to access a GP with no out-of-pocket cost for the consultation?\n",
       "            <b><font color=#FA8072>Answer</font></b>: 11.6 million"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>2</b>. <b><font color=#FF7F50>Question</font></b>: What will support 11.6 million Australians to access a GP with no out-of-pocket costs?\n",
       "            <b><font color=#FA8072>Answer</font></b>: The Government is tripling the incentive paid to GPs to bulk bill consultations for families with children under 16 years, pensioners and Commonwealth concession card holders, at a cost of $3.5 billion."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>3</b>. <b><font color=#FF7F50>Question</font></b>: How much of the bulk billing incentive will be paid to GPs to enable general practice consultations over 6 minutes in length\n",
       "            <b><font color=#FA8072>Answer</font></b>: $3.5 billion"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>4</b>. <b><font color=#FF7F50>Question</font></b>: What are the 2 ways the Government wants to increase access to primary care for Australians?\n",
       "            <b><font color=#FA8072>Answer</font></b>: Increasing access to primary care with coordinated teams"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>5</b>. <b><font color=#FF7F50>Question</font></b>: How much will each family, pensioner and Commonwealth concession card holder pay to see a GP without paying any out of pocket costs?\n",
       "            <b><font color=#FA8072>Answer</font></b>: $0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_qna_pairs(txt_aus_budget_overview_medicare, 5, output_style=QNA_OUTPUT_STYLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bb9bbb17-56ff-4607-9d80-88e623e51168",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'telehealth general practice services which are between 6 and 20 minutes in length'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(txt_aus_budget_overview_medicare,\"What is a Level B consultation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ee86044c-3f69-433c-89e4-b5ead1c17b55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$5.7 billion'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(txt_aus_budget_overview_medicare, \"How much is the govermement investing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6deec971-3be8-46e6-88e7-7d3be2d20d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Government will also invest in new services to help homeless people and culturally and linguistically diverse communities to access primary care.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(txt_aus_budget_overview_medicare, \"Is the governement helping the homeless people?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a83f98-c806-497e-b3f1-1e3aa5cf898b",
   "metadata": {},
   "source": [
    "## 4. [Optional] Education Part II デモ\n",
    "\n",
    "このセクションでは、URL を受け取る Gradio アプリケーションを作成し、ウェブページのコンテンツをベースに質問回答を行います。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c2f91c-56e4-497d-a107-d2a2824ebff0",
   "metadata": {},
   "source": [
    "### 4.1 Gradio Demo App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "11f4c760-b110-41d5-818f-cf848da229fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3c58ed7a-a92b-44c5-bfbb-74d7063b9bd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f803d584-df90-4e15-8923-0f19d7fb90cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def url2context(url):\n",
    "    paragraph_list = extract_paragraphs_from_html(\n",
    "        download_url_text(url)\n",
    "    )[1:11]  # We will skip the first paragraph, and take only 10 paragraphs\n",
    "    return '\\n\\n'.join(paragraph_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d43bd2c0-b8d6-4b39-8a77-06851e28184f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://c60adc167cc2915343.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://c60adc167cc2915343.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot(prompt, temperature, max_length, url):\n",
    "    if url == \"\":\n",
    "        return generate_text_from_prompt(prompt, max_length, temperature)\n",
    "    else:\n",
    "        return ask(url2context(url), prompt)\n",
    "\n",
    "def summary(url):\n",
    "    context = url2context(url)\n",
    "    key_words = generate_text_from_prompt(\n",
    "        f'FIND KEY WORDS\\n\\nContext:\\n{context}\\nKey Words:'\n",
    "    )\n",
    "    return f\"\"\"{summarize(context)}\\n\\nKey words: {key_words}\"\"\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Flan T5 Chatbot Demo\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            url = gr.Textbox(label=\"URL\", placeholder=\"Enter URL here\", lines=1, show_label=True,\n",
    "                             value=\"https://mmrjournal.biomedcentral.com/articles/10.1186/s40779-022-00416-w\"\n",
    "                             # value=\"https://k12.libretexts.org/Bookshelves/Science_and_Technology/Biology/03%3A_Genetics/3.14%3A_Human_Genome\"\n",
    "                            )\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            prompt = gr.Textbox(\n",
    "                label=\"Prompt\", placeholder=\"Enter your prompt here\", lines=3, show_label=True,\n",
    "                value=f\"How do mRNA vaccines work for pancreatic cancer treatment?\")\n",
    "            temperature = gr.Slider(label=\"Temperature\", minimum=0.0, maximum=1.0, value=0.5)\n",
    "            max_length = gr.Slider(label=\"Max Length\", minimum=20, maximum=400, value=100)\n",
    "        with gr.Column():\n",
    "            output = gr.Textbox(label=\"Output\", lines=10, show_label=True)\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            submit_btn = gr.Button(\"Submit\")\n",
    "        with gr.Column():\n",
    "            summary_btn = gr.Button(\"Summary\")\n",
    "    submit_btn.click(\n",
    "        fn=chatbot,\n",
    "        inputs=[prompt, temperature, max_length, url],\n",
    "        outputs=output,\n",
    "        api_name=\"chatbot\",\n",
    "        queue=False\n",
    "    )\n",
    "    summary_btn.click(\n",
    "        fn=summary,\n",
    "        inputs=[url],\n",
    "        outputs=output,\n",
    "        api_name=\"summary\",\n",
    "        queue=False\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a0cb52-4083-4368-94e5-2415bc108b60",
   "metadata": {},
   "source": [
    "## 5. クリーンアップ\n",
    "\n",
    "SageMaker モデルとエンドポイントを削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dd21b3e6-5055-41f5-9b8c-9faaeea66282",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting model with name: jumpstart-example-huggingface-text2text-2023-06-10-08-37-25-049\n",
      "Deleting endpoint configuration with name: jumpstart-example-huggingface-text2text-2023-06-10-08-37-25-049\n",
      "Deleting endpoint with name: jumpstart-example-huggingface-text2text-2023-06-10-08-37-25-049\n"
     ]
    }
   ],
   "source": [
    "model_predictor.delete_model()\n",
    "model_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a8d029-74e5-49fa-94db-0cec17d3a08c",
   "metadata": {},
   "source": [
    "File > Shut Down > Shutdown All と操作し、SageMakerを完全にシャットダウンします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2958a4-9981-4d23-84a4-e7d7b63ddfda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-northeast-1:102112518831:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
